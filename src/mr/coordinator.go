package mr

import (
	"errors"
	"fmt"
	"log"
	"net"
	"net/http"
	"net/rpc"
	"os"
	"sync"
	"time"
)

type Coordinator struct {
	// Your definitions here.
	files       []string
	nReduce     int
	nodeId      int // dispatch task with a node id to identify temp files generated by different nodes
	nodeIdMutex sync.Mutex

	mapStates []int // 0:not dispatched, 1:dispatched, 2:done, 3:dispatched_timeout
	mapIds    []int
	mapDone   bool
	mapMutex  sync.Mutex

	reduceStates []int // 0:not dispatched, 1:dispatched, 2:done, 3:dispatched_timeout
	reduceIds    []int
	reduceDone   bool
	reduceMutex  sync.Mutex
}

func (c *Coordinator) searchFileName(filename string) int {
	for i, file := range c.files {
		if file == filename {
			return i
		}
	}
	return -1
}

func (c *Coordinator) checkMapDone() bool {
	for _, state := range c.mapStates {
		if state != 2 {
			return false
		}
	}
	return true
}

func (c *Coordinator) checkReduceDone() bool {
	for _, state := range c.reduceStates {
		if state != 2 {
			return false
		}
	}
	return true
}

// Your code here -- RPC handlers for the worker to call.

//
// an example RPC handler.
//
// the RPC argument and reply types are defined in rpc.go.
//
func (c *Coordinator) Example(args *ExampleArgs, reply *ExampleReply) error {
	st := &ExampleSt{"i win"}
	reply.S = st
	reply.Y = 222
	reply.STRR = "GSG"
	// fmt.Printf("reply:%v\n", reply)

	return nil
}

func (c *Coordinator) DispatchTask(args *RPCArgs, reply *RPCReply) error {
	c.mapMutex.Lock()
	//fmt.Printf("locked\n")
	//fmt.Printf("c.mapStates: %v\n", c.mapStates)
	if !c.mapDone {
		// find a map task
		for i, state := range c.mapStates {
			if state == 0 {
				//fmt.Printf("dispatching map task %v, id:%v\n", i, c.nodeId)
				//fmt.Printf("args:%v\n", args)
				//fmt.Printf("origin reply:%v\n", reply)
				c.mapStates[i] = 1
				reply.TaskType = TASK_MAP
				reply.NReduce = c.nReduce
				reply.MapIndex = i
				reply.FileName = c.files[i]
				c.nodeIdMutex.Lock()
				reply.NodeId = c.nodeId
				c.mapIds[i] = c.nodeId
				c.nodeId++
				c.nodeIdMutex.Unlock()
				//fmt.Printf("mapindex:%v, reply dispatched:%v\n", i, reply)
				//c.mutex.Unlock()
				//fmt.Printf("unlocked\n")
				c.mapMutex.Unlock()

				// delete temp file remained by previous broken nodes
				for j := 0; j < c.nReduce; j++ {
					filename := fmt.Sprintf("mr-%v-%v-tmp", i, j)
					os.Remove(filename)
				}

				return nil
			}
		}
		c.mapMutex.Unlock()
	} else {
		c.mapMutex.Unlock()
		c.reduceMutex.Lock()
		// find a reduce task
		for i, state := range c.reduceStates {
			if state == 0 {
				//fmt.Printf("dispatching reduce task %v, id:%v\n", i, c.nodeId)
				c.reduceStates[i] = 1
				reply.TaskType = TASK_REDUCE
				reply.ReduceIndex = i
				reply.TotalMapNum = len(c.files)
				c.nodeIdMutex.Lock()
				reply.NodeId = c.nodeId
				c.reduceIds[i] = c.nodeId
				c.nodeId++
				c.nodeIdMutex.Unlock()
				//c.mutex.Unlock()
				//fmt.Printf("unlocked\n")
				c.reduceMutex.Unlock()

				// delete temp file remained by previous broken nodes
				filename := fmt.Sprintf("mr-out-%v-tmp", i)
				os.Remove(filename)

				return nil
			}
		}
		c.reduceMutex.Unlock()
	}

	c.reduceMutex.Lock()
	if c.reduceDone {
		reply.TaskType = TASK_NONE
	} else {
		reply.TaskType = TASK_WAIT
	}
	c.reduceMutex.Unlock()
	//c.mutex.Unlock()
	//fmt.Printf("unlocked\n")
	return nil
}

func (c *Coordinator) HandleTaskDone(args *RPCArgs, reply *RPCReply) error {
	//fmt.Printf("c.mapStates: %v\n", c.mapStates)
	//fmt.Printf("task done %v\n", args)
	if args.TaskType == TASK_MAP {
		i := c.searchFileName(args.FileName)
		if i == -1 {
			return errors.New("handleTaskDone task index error")
		}

		c.mapMutex.Lock()
		defer c.mapMutex.Unlock()
		if c.mapStates[i] == 2 {
			return nil
		}
		c.mapStates[i] = 2
		if c.checkMapDone() {
			c.mapDone = true
		}

		for j := 0; j < c.nReduce; j++ {
			oldName := fmt.Sprintf("mr-%v-%v-%v", i, j, args.NodeId)
			newName := fmt.Sprintf("mr-%v-%v", i, j)
			os.Rename(oldName, newName)
		}
	} else if args.TaskType == TASK_REDUCE {
		c.reduceMutex.Lock()
		defer c.reduceMutex.Unlock()
		if c.reduceStates[args.ReduceIndex] == 2 {
			return nil
		}
		c.reduceStates[args.ReduceIndex] = 2
		if c.checkReduceDone() {
			c.reduceDone = true
		}

		oldName := fmt.Sprintf("mr-out-%v-%v", args.ReduceIndex, args.NodeId)
		newName := fmt.Sprintf("mr-out-%v", args.ReduceIndex)
		os.Rename(oldName, newName)
	} else {
		return errors.New("handleTaskDone task type error")
	}

	return nil
}

//
// start a thread that listens for RPCs from worker.go
//
func (c *Coordinator) server() {
	rpc.Register(c)
	rpc.HandleHTTP()
	//l, e := net.Listen("tcp", ":1234")
	sockname := coordinatorSock()
	os.Remove(sockname)
	l, e := net.Listen("unix", sockname)
	if e != nil {
		log.Fatal("listen error:", e)
	}
	go http.Serve(l, nil)
}

//
// main/mrcoordinator.go calls Done() periodically to find out
// if the entire job has finished.
//
func (c *Coordinator) Done() bool {
	// your code here
	c.reduceMutex.Lock()
	defer c.reduceMutex.Unlock()
	return c.reduceDone
}

// func (c *Coordinator) checkDispatchedTasks() {

// 	time.Sleep(10 * time.Second)
// }

//
// create a Coordinator.
// main/mrcoordinator.go calls this function.
// nReduce is the number of reduce tasks to use.
//
func MakeCoordinator(files []string, nReduce int) *Coordinator {
	c := Coordinator{}

	// Your code here.
	c.files = files
	c.mapStates = make([]int, len(files))
	c.mapIds = make([]int, len(files))
	//fmt.Println(c.mapStates)
	c.reduceStates = make([]int, nReduce)
	c.reduceIds = make([]int, nReduce)
	//fmt.Println(c.reduceStates)
	c.nReduce = nReduce
	//fmt.Printf("nreduce %v\n", c.nReduce)
	c.mapDone = false
	c.reduceDone = false

	go func() {
		for {
			if c.Done() {
				break
			}
			//fmt.Printf("checking timeout\n")
			time.Sleep(10 * time.Second)
			c.mapMutex.Lock()
			for i, state := range c.mapStates {
				if state == 1 {
					c.mapStates[i] = 3
				} else if state == 3 {
					//fmt.Printf("map timeout %v\n", i)
					c.mapStates[i] = 0
				}
			}
			c.mapMutex.Unlock()
			c.reduceMutex.Lock()
			for i, state := range c.reduceStates {
				if state == 1 {
					c.reduceStates[i] = 3
				} else if state == 3 {
					//fmt.Printf("reduce timeout %v\n", i)
					c.reduceStates[i] = 0
				}
			}
			c.reduceMutex.Unlock()
		}
	}()

	c.server()
	return &c
}
